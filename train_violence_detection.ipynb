{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_violence_detection",
      "provenance": [],
      "mount_file_id": "1fIJ5URxo2KidbLsEcAqJZwEoLe14qAma",
      "authorship_tag": "ABX9TyP+2Jre3ydg2YoABO4nSxcE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nigitha-16/Violence-Detection-in-Surveillance-Video/blob/master/train_violence_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVioOHyg2bya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Flatten\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD, Adagrad,Adam\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from numpy import savetxt\n",
        "from numpy import loadtxt\n",
        "from keras.regularizers import l2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqpiduvx27Ws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initializer = tf.keras.initializers.GlorotNormal()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHuurF0m1jip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(512, input_dim=4096,kernel_regularizer='l2',kernel_initializer=initializer,activation='relu'))\n",
        "  #model.add(Dropout(0.6))\n",
        "  model.add(Dense(32,kernel_regularizer='l2',kernel_initializer=initializer))\n",
        "  #model.add(Dropout(0.6))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmXFu6_Z4tbU",
        "colab_type": "text"
      },
      "source": [
        "Load features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOiNv5ZX4172",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### load the csv file containing features ###\n",
        "ar=loadtxt('/content/drive/My Drive/train_anom_nom_feat.csv',delimiter=',')\n",
        "\n",
        "ar_anom=ar[:34*32]\n",
        "ar_nom=ar[34*32:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUNsEEik2qFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset_Train_batch(ar_nom=ar_nom,ar_anom=ar_anom,batch_size=8):\n",
        "\n",
        "  n_vid_each=int(batch_size/2) #number of videos in each category\n",
        "\n",
        "  count=-1\n",
        "\n",
        "  #### generate random index ####\n",
        "  Abnorm_iter = np.random.permutation(34)\n",
        "  Abnorm_iter = Abnorm_iter[:n_vid_each] \n",
        "  Norm_iter = np.random.permutation(40)\n",
        "  Norm_iter = Norm_iter[:n_vid_each]   \n",
        "\n",
        "  Features = []\n",
        "\n",
        " \n",
        "  for f in Abnorm_iter:\n",
        "\n",
        "    feat = ar_anom[f*32:f*32+32] ####each video has 32 segments\n",
        "    count = count + 1\n",
        "    if count == 0:\n",
        "        Features = feat\n",
        "    if count > 0:\n",
        "        Features = np.append(Features, feat,axis=0)\n",
        "  \n",
        "\n",
        "  AllFeatures = Features\n",
        "  count=-1\n",
        "  for f in Norm_iter:\n",
        "    feat = ar_nom[f*32:f*32+32]  ####each video has 32 segments\n",
        "    count = count + 1\n",
        "    if count == 0:\n",
        "        Features = feat\n",
        "    if count > 0:\n",
        "        Features = np.append(Features, feat,axis=0)\n",
        "  \n",
        "\n",
        "  ###### stack the normal features over the abnormal #####\n",
        "  AllFeatures = np.vstack((AllFeatures, Features))\n",
        "\n",
        "  ######## labels #######\n",
        "  l_0 = np.ones(32*n_vid_each, dtype='uint8') ## 1 for abnormal\n",
        "  l_1= np.zeros(32*n_vid_each, dtype='uint8') ## 0 for normal\n",
        "  all_labels=np.append(l_0,l_1,axis=0)\n",
        "  return AllFeatures,all_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P94AR6oE6HJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### define the loss function ##########\n",
        "def custom_loss(y_true, y_pred):\n",
        "    \n",
        "    'Custom Objective function'\n",
        "    \n",
        "    y_true = tf.reshape(y_true,[-1])\n",
        "    y_pred = tf.reshape(y_pred,[-1])\n",
        "\n",
        "    n_seg = 32  \n",
        "    batch_size = 8\n",
        "    n_vid_each = int(batch_size / 2)\n",
        "    total_feat=32*batch_size\n",
        "\n",
        "\n",
        "    s_max = tf.ones_like(y_pred) # holds the highest scoring instance\n",
        "    s_l1=tf.cast(tf.ones_like(y_true),'float32')  # holds l1 score\n",
        "    s_l2 =tf.cast(tf.ones_like(y_true),'float32') # holds the l2 score\n",
        "\n",
        "    for ii in range(batch_size):\n",
        "        # For Labels\n",
        "        mm = y_true[ii * n_seg:ii * n_seg + n_seg]\n",
        "      \n",
        "        # For Features scores\n",
        "        seg_score = y_pred[ii * n_seg:ii * n_seg + n_seg]\n",
        "        s_max = tf.concat([s_max, tf.reshape(tf.math.reduce_max(seg_score),[1])],0) # maximum score of scores \n",
        "        s_l1 = tf.concat([s_l1, tf.reshape(tf.math.reduce_sum(seg_score),[1])],0)   # sum of scores of all instances \n",
        "        z1 = tf.ones_like(seg_score)\n",
        "        z2 = tf.concat([z1, seg_score],0)\n",
        "        z3 = tf.concat([seg_score, z1],0)\n",
        "        z = z2[31:] - z3[:33]\n",
        "        z = z[1:32]\n",
        "        z = tf.math.reduce_sum(tf.math.square(z))\n",
        "        s_l2 = tf.concat([s_l2, tf.reshape(z,[1])],0)\n",
        "\n",
        "    \n",
        "    sub_score = s_max[total_feat:]  # We need this step since we have used tf.ones_like\n",
        "    \n",
        " \n",
        "    s_l1 = s_l1[total_feat:] # We need this step since we have used tf.ones_like\n",
        "    s_l1 = s_l1[:n_vid_each]\n",
        "    s_l2 = s_l2[total_feat:] # We need this step since we have used tf.ones_like\n",
        "    s_l2 = s_l2[:n_vid_each]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    Sub_Nor = sub_score[n_vid_each:] # Maximum Score for each of abnormal video\n",
        "    Sub_Abn = sub_score[:n_vid_each] # Maximum Score for each of normal video\n",
        "\n",
        "    \n",
        "    z=tf.maximum(tf.reduce_sum(1-Sub_Abn+Sub_Nor),0)+  0.008*tf.math.reduce_sum(s_l1) + 0.008*tf.math.reduce_sum(s_l2) ### final loss \n",
        "    \n",
        "    return z\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5sv2hy5Oqvy",
        "colab_type": "text"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06BIQzBLA1Qz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adagrad=Adagrad(lr=0.01, epsilon=1e-07)\n",
        "model=build_model()\n",
        "\n",
        "model.compile(loss=custom_loss, optimizer=adagrad)\n",
        "\n",
        "print(\"Starting training...\")\n",
        "\n",
        "loss_graph =[]\n",
        "num_iters = 2000\n",
        "total_iterations = 0\n",
        "batch_size=8\n",
        "\n",
        "\n",
        "for it_num in range(num_iters):\n",
        "\n",
        "\n",
        "    inputs, targets=load_dataset_Train_batch(ar_nom,ar_anom,batch_size)  # Load normal and abnormal video C3D features\n",
        "    batch_loss =model.train_on_batch(inputs, targets)\n",
        "    \n",
        "    loss_graph = np.hstack((loss_graph, batch_loss))\n",
        "    if total_iterations%200 ==0:\n",
        "      model.save_weights('/content/drive/My Drive/model_weights_violence_detection.h5')\n",
        "      print(batch_loss)\n",
        "    total_iterations += 1\n",
        "plt.plot(loss_graph)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}